%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Methodologie}{Methodology}}
\label{ch:methodologie}

\section{Plan van aanpak}

De meest effectieve benadering voor het uitvoeren van dit onderzoek omvat een reeks stappen. Allereerst wordt de data-acquisitie uitgevoerd om relevante gegevens te verzamelen. Het is van essentieel belang om te bepalen waar de meest geschikte bronnen zijn om de benodigde data te verkrijgen en welke methoden kunnen worden toegepast.

Na het succesvol verzamelen van de data, volgt het proces van datafiltering, waarbij onnodige rijen en kolommen worden verwijderd en de aanwezigheid van bruikbare informatie wordt geëvalueerd.

Zodra alle vereiste data beschikbaar is, wordt de data voorbereid voor het gedeelte van machinaal leren met behulp van geschikte Python-bibliotheken. Daarnaast wordt er een analyse uitgevoerd op de data om mogelijk interessante bevindingen en conclusies te identificeren.

Vervolgens wordt het best mogelijke AI-model getraind. Verschillende modellen zullen worden geëvalueerd en getest om het meest optimale model te identificeren. Dit model zal verder worden verfijnd om een nauwkeurigheidsscore van 95\% te behalen.

Ten slotte zal er een kleine applicatie worden ontwikkeld waarin gebruikers de mogelijkheid krijgen om, op basis van het getrainde model, voorspellingen te doen over schaakpartijen tussen twee grootmeesters. Om een applicatie te genereren, kan de code lokaal worden uitgevoerd of kan het commando 'pyinstaller --onefile bestandsnaam.py' worden gebruikt. Dit commando resulteert in de creatie van een uitvoerbaar bestand dat de code in de vorm van een applicatie laat draaien.

Door deze methodische aanpak kan het onderzoek gestructureerd worden uitgevoerd, waarbij de focus ligt op het verkrijgen van betrouwbare data, het analyseren ervan, het trainen van een nauwkeurig AI-model en het ontwikkelen van een gebruiksvriendelijke applicatie. 

\section{Ophalen data}

\subsection{Data extrusion}

In het kader van deze bachelorproef werd als eerste stap gekeken naar de meest geschikte bron voor het verkrijgen van de benodigde data. Voordat bepaald wordt waar de data verkrijgbaar zijn, is het essentieel om de vraag te stellen: Welke specifieke data zijn nodig?

Het doel van dit onderzoek is om een model te trainen dat de uitkomst van toekomstige schaakpartijen kan voorspellen op basis van gespeelde partijen. Aangezien het onderzoek zich uitsluitend richt op grootmeesters, zijn alleen partijen nodig die gespeeld zijn tussen twee grootmeesters. Bovendien is het belangrijk om te weten welke spelers bij welke partij betrokken waren, welke rating ze op dat moment hadden en met welke kleur ze elk speelden.

Er zijn verschillende databases die partijen bevatten die aan de gestelde criteria voldoen. Websites en applicaties zoals ChessBase, Chess.com, Lichess en vele anderen bieden de meeste benodigde data voor dit onderzoek. De keuze is echter gevallen op het verkrijgen van data van de officiële FIDE-website, omdat FIDE de belangrijkste coördinator is van professioneel schaken. Bovendien bleek uit de functionaliteit van de FIDE-zoekmachine dat die kan filteren op grootmeesters, actieve spelers en partijlengte. Deze veelzijdige filteringsopties waren overtuigend genoeg om deze bron te verkiezen.

Voor het verkrijgen van de data waren er drie mogelijke benaderingen:

\begin{itemize}
    \item Het gebruik van een door een internationale FIDE-scheidsrechter ontwikkelde Python-parser \autocite{Larreategi}
    \item Een webscraper van de GitHub-repository van \textcite{Alves2020}
    \item Het ontwikkelen van een eigen API en scraper.
\end{itemize}

Het oorspronkelijke plan was om eerst te onderzoeken of één van de eerste twee opties haalbaar was voordat werd overwogen om zelf een API te ontwikkelen. Er is gestart met het verkennen van de Python-scraper van Mikel Larreategi. Al snel werd echter een probleem ontdekt. De scraper was oorspronkelijk bedoeld om alleen toernooipartijen op te halen. Daarnaast was de verzamelde informatie niet bruikbaar voor het beoogde doel. Belangrijke spelersgegevens, zoals hun ELO-rating, ontbraken, terwijl overbodige informatie, zoals de betrokken scheidsrechters bij elke partij, wel aanwezig was. Het werd al snel duidelijk dat deze benadering niet geschikt was om te volgen.

Op het eerste gezicht leek de tweede optie niet erg veelbelovend, aangezien de API al geruime tijd geleden was ontwikkeld en mogelijk niet meer up-to-date was. Bovendien was de volledige implementatie in JavaScript en was er geen ingebouwde Python-scraper die met de API kon werken. Nader onderzoek onthulde echter een kleine scraper in de GitHub-repository aanwezig te zijn die profielgegevens kon ophalen van elke geregistreerde speler op de FIDE-website, mits de speler-ID bekend was. De speler-ID is niet gebaseerd op de rating of ranglijst van de speler, maar eerder op het tijdstip van toevoeging aan de database of een willekeurige toewijzing.

De bestaande scraper leverde niet alle benodigde data op, maar diende als een nuttige basis om een aangepaste scraper te ontwikkelen. Door gebruik te maken van de reeds bestaande API in de GitHub-repository, kon ik het probleem benaderen door twee oplossingen te combineren. Hierdoor kon ik de ontbrekende data aanvullen en een meer uitgebreide dataset verkrijgen.

Een belangrijk voordeel van deze repository is de MIT-licentie die eraan verbonden is. Deze licentie luidt als volgt: "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so." Het enige vereiste voor het gebruik van de software is het opnemen van de bovenstaande auteursrechtvermelding en toestemmingsverklaring in alle kopieën of substantiële delen van de software.

\subsection{Doelstelling}

De beschikbare scraper in de GitHub-repository biedt de mogelijkheid om de profielgegevens van individuele spelers op te halen. Zodra deze informatie wordt verkregen, is er echter alleen toegang tot de profielgegevens van de spelers, terwijl onze interesse voornamelijk uitgaat naar de volledige partijgeschiedenis van elke speler. Deze partijgeschiedenis omvat alle gespeelde partijen gedurende de gehele carrière van de betreffende spelers.

Deze partijgeschiedenis vormt de basis voor de gewenste dataset. Het verkrijgen van de volledige partijgeschiedenis voor elke individuele speler zou ons in staat stellen om alle benodigde gegevens te verwerven voor ons onderzoek.

\subsection{Spelerdata}

De API is geïmplementeerd in JavaScript, maar gezien mijn ervaring met die taal, ligt mijn expertise niet bij het ontwikkelen van een scraper in JavaScript. Mijn voorkeur gaat eerder uit naar het gebruik van Python voor dit doeleinde, aangezien ik vertrouwd ben met het schrijven van scrapers in deze programmeertaal.

Het plan is dan ook om de scraper te implementeren in Python, met behulp van de bibliotheek Beautiful Soup 4. Beautiful Soup is een Python-bibliotheek waarmee gegevens rechtstreeks in het UTF-8-formaat kunnen worden geëxtraheerd van een website. Deze keuze biedt de mogelijkheid aan om gebruik te maken van de functionaliteiten en flexibiliteit die Python heeft bij het ontwikkelen van de scraper.\autocite{Richardson}

\begin{lstlisting}[language=Python]
    import re
    import requests
    from bs4 import BeautifulSoup
    
    # get fide ids
    print("Getting fide ids")
    fide_ids_url = f"https://ratings.fide.com/incl_search_l.php?search=&search_rating={rating}&search_country=all&search_title={title}&search_other_title=all&search_year=undefined&search_low=0&search_high=3500&search_inactive=on&search_exrated=off&search_radio=rating&search_bday_start=all&search_bday_end=all&search_radio=rating&search_asc=descending&search_gender=undefined&simple=0"
    fide_ids_html = requests.get(fide_ids_url, headers={'X-Requested-With': 'XMLHttpRequest'}).text
    soup = BeautifulSoup(fide_ids_html, 'html.parser')
    anchors = soup.find_all('a')
    hrefs = [a.get('href') for a in anchors]
    pattern = re.compile(r"/profile/(\d+)")
    fide_ids = [pattern.search(href).group(1) for href in hrefs if pattern.search(href)]
\end{lstlisting}

Hierbij worden alle ID's opgehaald van profielen naar keuze met behulp van BeautifulSoup. Het starten van dit script zorgt ervoor dat een applicatie opstart die vraagt aan de gebruiker om te kiezen uit standaard, rapid of blitz (de drie tijdsmodules). Nadat die keuze is gemaakt, vraagt het programma ook welke filter je wilt kiezen. Dit is een filter dat een lijst weergeeft met alle mogelijke titels, waaronder de titel grootmeesteer. De data die kan opgehaald worden is dus flexibel maar voor de doeleinden van dit project, worden enkel de partijen van de grootmeesters opgehaald. Zo zijn alle ID's van alle actieve grootmeesters bemachtigd.

\begin{lstlisting}[language=Python]
    import re
    import subprocess
    import pandas as pd
    from tqdm import tqdm
    
    # get info of players
    print("Getting info of players")
    
    players = []
    process = subprocess.Popen("fide-ratings-scraper api", stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
    for i in tqdm(range(len(fide_ids))):
        fide_id = fide_ids[i]
        response = requests.get(f"http://localhost:3000/player/{fide_id}/info")
        player = response.json()
        player["fide_id"] = fide_id
        player["name"] = player["name"].strip()
        players.append(player)
    process.kill()
    
    # print out data to csv
    df = pd.DataFrame(players)
    df.to_csv(f"fide_players_{rating}_{title}.csv", index=False)
\end{lstlisting}

In dit proces worden met behulp van Beautiful Soup alle ID's van geselecteerde profielen opgehaald. Bij het starten van dit script wordt een applicatie geïnitialiseerd, waarin de gebruiker wordt gevraagd om een keuze te maken uit de standaard-, rapid- of blitzmodus (de drie beschikbare tijdsmodules). Nadat deze keuze is gemaakt, wordt de gebruiker ook gevraagd welk filter hij of zij wenst toe te passen.

Deze filter stelt een lijst samen met alle mogelijke titels, waaronder de titel "grootmeester". Het is belangrijk op te merken dat de op te halen data flexibel zijn. Voor de specifieke doeleinden van dit onderzoek wordt de focus gelegd op het verkrijgen van de ID's van actieve grootmeesters. Hierdoor worden alle ID's van de huidige grootmeesters verzameld, wat van cruciaal belang is voor het onderzoek.\autocite{NumFocus}

\subsection{Historiek}

Op het eerste gezicht lijkt de tussenstap voor het ophalen van spelergegevens misschien overbodig, aangezien er gebruik gemaakt wordt van een ID om profielinformatie op te halen. Is het echter mogelijk om ook de partijgeschiedenis op te halen? Zeker, maar hier doet zich een probleem voor: in de partijgeschiedenis van een speler wordt alleen de naam van de tegenstander vermeld, niet de bijbehorende ID. Het was essentieel om de ID's van elke speler aan een specifieke naam te koppelen, zodat er kan gecontroleerd wordt of de tegenstander op de lijst van grootmeesters staat. De code is zo ontworpen dat deze schaalbaar is voor het geval iemand alle wedstrijden van een groep spelers wil ophalen zonder dat er een filter wordt toegepast op een reeds bestaand CSV-bestand.

\begin{lstlisting}[language=Python]
    import re
    import pandas as pd
    
    #get games of player
    player_games = []

    def output_player_games(player_games):
        df = pd.DataFrame(player_games)
        match = re.search(r'fide_players_(.+)_([^\.]+)\.csv', players_file_name)
        if not opponents_from_csv:
            df.to_csv(f"fide_games_{match.group(1)}_{match.group(2)}_all.csv", index=False)
        else:
            df.to_csv(f"fide_games_{match.group(1)}_{match.group(2)}_oppfromcsv.csv", index=False)
\end{lstlisting}

Binnen de applicatie krijgt een gebruiker de mogelijkheid om aan te geven of er al dan niet moet worden gefilterd op naam. Indien de eindgebruiker ervoor kiest om geen filtering toe te passen tijdens het scrapproces, zal het programma het if-statement doorlopen. Daarentegen, indien de eindgebruiker wel filtering wenst, zal de scraper het else-statement volgen. Deze aanpak stelt ons in staat om meerdere CSV-bestanden te genereren voor verschillende doeleinden. Voor dit specifieke project, is er ervoor gekozen om te filteren op de naam. Dit besluit is genomen omdat er enkel interesse is in partijen waarbij een grootmeester tegen een andere grootmeester speelt.

\section{Filtering data}

\subsection{Verstandhouding}

Tijdens het scraping-proces zijn drie csv-bestanden gegenereerd, elk bestand vertegenwoordigt een specifieke tijdscategorie (standaard, blitz en rapid). Deze csv-bestanden bevatten uitgebreide informatie over partijen gespeeld tussen grootmeesters. Ze omvatten verschillende kolommen die als volgt zijn gestructureerd:

\begin{itemize}
    \item Datum
    \item Naam speler
    \item Naam tegenstander
    \item w => uitkomst van de partij
    \item n => som uitkomst van beide spelers
    \item chg => changerate (zal later op dieper ingegaan worden)
    \item k => katalysator/factor
    \item kchg => k vermenigvuligd met chg (elo gain/loss)
    \item Evenement
    \item Locatie
    \item Land van afkomst speler
    \item Titel speler
    \item Rating tegenstander
    \item Land van afkomst tegenstander 
    \item Titel tegenstander
    \item Kleur => kleur van speler
\end{itemize}

Hoewel technisch gezien alle benodigde gegevens verzameld zijn, doen zich echter snel drie problemen voor.

\subsection{Problematiek}

Probleem 1: Er zijn verschillende overbodige kolommen met data die weinig tot geen toegevoegde waarde bieden. Dit geldt met name voor de kolommen 'Titel speler' en 'Titel tegenstander'. Aangezien de eerder vermelde scrapers zijn ingesteld met filters om alleen grootmeesters op te nemen in de dataset, bevatten deze kolommen redundantie.

Probleem 2: De rating van de tegenstander wordt vermeld op elke regel. Deze rating is een dynamische waarde, aangezien de ELO-rating van elke speler pas wordt bijgewerkt op de dag nadat ze hun partijen hebben gespeeld. Hoewel deze langzaam veranderende waarde correct is voor elke grootmeester, ontbreekt er een kolom met de ELO-rating van de speler zelf. Hierdoor is het niet mogelijk om een directe vergelijking te maken van het vaardigheidsniveau tussen de twee spelers.

Probleem 3: Er is een duplicatie van partijen in het bestand. Als speler X tegen speler Y een partij heeft gespeeld op datum Z, dan zal deze informatie ook voorkomen in de historie van speler Y. Op dezelfde manier zal er een record in het CSV-bestand zijn waarbij speler Y tegen speler X heeft gespeeld op dezelfde dag Z. Dit leidt tot dubbele gegevens en kan een probleem vormen bij het trainen van een model, omdat dit de nauwkeurigheid van het model kan beïnvloeden.

\subsection{Oplossingen}

Het eerste probleem kan op een relatief eenvoudige manier worden aangepakt. De applicatie zal de overbodige kolommen verwijderen. Het uitdagendste aspect van dit proces is echter het maken van de juiste keuze welke kolommen verwijderd moeten worden. Dit vereist zorgvuldige afweging en het bepalen van welke kolommen weinig tot geen toegevoegde waarde bieden voor de analyse of het beoogde doel van de gegevensverwerking. Het is belangrijk om rekening te houden met de specifieke vereisten en doelstellingen van het project om een weloverwogen beslissing te nemen over welke kolommen behouden moeten blijven en welke kunnen worden verwijderd.

\begin{lstlisting}[language=Python]
    import pandas as pd
    df_games = pd.read_csv(games_file_name)
    df_games = df_games.drop('k', axis=1)
    df_games = df_games.drop('chg', axis=1)
    df_games = df_games.drop('n', axis=1)
    df_games = df_games.drop('event', axis=1)
    df_games = df_games.drop('location', axis=1)
    df_games = df_games.drop('country', axis=1)
    df_games = df_games.drop('opponent_country', axis=1)
    df_games = df_games.drop('opponent_title', axis=1)
    df_games = df_games.drop('player_title', axis=1)
\end{lstlisting}

De kolom 'k' wordt verwijderd omdat deze kolom dezelfde waarde bevat voor alle grootmeesters. Volgens het regulatiedocument opgesteld door de \textcite{FIDE2021}, vertegenwoordigt 'k' de ontwikkelingscoëfficiënt. Rating-systemen behandelen spelers die lange tijd niet hebben gespeeld of nieuw zijn in het schaken als 'volatile'. Dit betekent dat hun rating-verandering sterker wordt beïnvloed. Het belangrijke detail van deze statistiek is dat de waarde van 'k' voor alle grootmeesters gelijk is aan tien. Dit komt doordat zodra een speler een ELO-rating van 2400 bereikt, deze factor automatisch wordt vastgesteld op tien, ongeacht of het oorspronkelijk twintig, dertig of veertig was. Hoewel dit van invloed is op de ELO-winst en ELO-verlies na een partij, is dit voor onze dataset niet relevant en heeft het geen effect. Het kan echter wel een belangrijke factor zijn voor schaalbaarheid, mocht er in de toekomst onderzoek worden gedaan naar nationale meesters of FIDE-meesters, waarbij het trainen van een model beïnvloed kan worden door deze factor.


De kolom 'chg' vertegenwoordigt de kans dat een speler wint of verliest. In de literatuurstudie is dit aspect nader onderzocht en gezien de aanwezigheid van de 'volatility-factor' die al wordt meegenomen in 'kchg', is het voor dit onderzoek beter om de kolom 'chg' te verwijderen. Aangezien beide kolommen technisch gezien dezelfde data bevatten, met alleen het verschil dat de waarden in 'kchg' vermenigvuldigd zijn met een factor van tien ten opzichte van 'chg', is het logischer om 'chg' te laten vallen en 'kchg' te behouden. Hierdoor kunnen we ons concentreren op de ELO-winst/-verlies in 'kchg' voor elke partij, wat meer relevant is voor het onderzoek.

De kolom 'n' vertegenwoordigt de totale waarde van de uitkomst van de spelers. Aangezien schaken een nul-som spel is, wat betekent dat het totale aantal gewonnen spellen gelijk is aan het totale aantal verloren spellen, zal deze waarde altijd hetzelfde zijn voor elke rij in het dataset. De totale waarde is in dit geval één, omdat een winnende speler één punt ontvangt, de verliezende speler nul punten krijgt, en bij een gelijkspel ontvangen beide spelers een half punt.

De kolommen 'locatie' en 'evenement' zouden normaal gesproken geen significante invloed moeten hebben op de data. In tegenstelling tot sporten zoals voetbal of andere sporten waarbij supporters psychologische aanmoediging, prestatiedruk of stress kunnen veroorzaken, is dit bij schaken niet het geval. Schaakzalen zijn meestal afgesloten om afleiding te minimaliseren, en hoewel de locatie mogelijk een verschil kan maken in slaapritme, zorgen de meeste professionele schakers ervoor dat externe factoren hen niet beïnvloeden. Schaken is een mentaal spel waarbij het behouden van een heldere geest cruciaal is, en daarom worden externe factoren die iemand kunnen afleiden doorgaans geminimaliseerd.

Het land van herkomst voor beide spelers zou naar verwachting geen invloed moeten hebben op de dataset. In tegenstelling tot bijvoorbeeld paardenraces, waarbij atleten uit bepaalde regio's mogelijk fysieke voordelen hebben als gevolg van training op grote hoogte, geldt dit niet voor schaken. De prestaties van een schaker zijn voornamelijk gebaseerd op zijn of haar kennis en vaardigheden in het spel. Het vermijden van landgebonden factoren helpt ook om te voorkomen dat bepaalde landen oververtegenwoordigd of ondervertegenwoordigd worden in de dataset. Een goed voorbeeld hiervan is Magnus Carlsen, die afkomstig is uit Noorwegen en daar vele sterke tegenstanders heeft. Als het AI-model gevoelig zou zijn voor het land van herkomst, zou het mogelijk verkeerde conclusies kunnen trekken op basis van deze specifieke situatie.

Ten slotte zijn de titels van de spelers ook niet langer relevant voor de dataset, omdat alle spelers in de dataset de titel "grootmeester" (g) hebben en de dataset al gefilterd is op alleen grootmeesters. Daarom kunnen de kolommen met de spelers' titels veilig worden verwijderd, aangezien ze geen extra waarde toevoegen aan de analyse.

Het tweede probleem kan op een elegante manier worden opgelost met een duidelijke aanpak, maar de implementatie van deze oplossing was uitdagend.

\begin{lstlisting}[language=Python]
    df_games_rating = df_games[['date','player_name','opponent_name','opponent_rating']]
    def find_cr(row):
        df_result = df_games_rating[(df_games_rating.date == row.date) & (df_games_rating.player_name == row.opponent_name) & (df_games_rating.opponent_name == row.player_name)]
        return str(df_result.opponent_rating.values[0]) if not df_result.empty else ''
    df_games['current_rating'] = df_games[['date','player_name','opponent_name','opponent_rating']].apply(find_cr, axis=1)
\end{lstlisting}

Het doel van de code is dat we een nieuwe kolom 'current rating' aanmaken waarbij de rating van de speler kan getoond worden dat die persoon had op die dag tegen zijn tegenstander. Het programma zal de huidige ELO-rating van de speler als 'df result' opslaan. Deze waarde wordt opgehaald door de record te zoeken waarbij de datum gelijk is aan de originele record, en waarbij 'naam speler' en 'naam tegenstander' omgewisseld zijn. Als het programma dan deze record heeft gevonden, zal het de rating van de tegenstander teruggeven (wat gelijk is aan de rating van de speler waarna we het op zoek waren). Dan zal er een nieuwe kolom aangemaakt worden waarbij deze waarde zal aan toegevoegd worden. Het argument axis=1 geeft aan dat de sorteerbewerking moet worden toegepast op elke rij. 

Het probleem werd aangepakt met een lambda-functie, maar helaas leverde dit geen succes op en veroorzaakte het problemen. De huidige beschreven aanpak heeft daarentegen wel gewerkt.

Het laatste probleem kan op een vergelijkbare manier worden opgelost.

\begin{lstlisting}[language=Python]
    df_sorted = df_games.copy()
    df_sorted[['date','player_name', 'opponent_name']] = df_sorted[['date','player_name', 'opponent_name']].apply(sorted, axis=1, result_type='expand')
    name_not_switched = (df_sorted['player_name'] == df_games['player_name'])
    df_games = df_sorted.loc[name_not_switched]
\end{lstlisting}

De oorspronkelijke DataFrame 'df games' wordt gekopieerd naar 'df sorted' om de oorspronkelijke gegevens te behouden tijdens het uitvoeren van wijzigingen. Vervolgens worden de kolommen 'date', 'player name' en 'opponent name' van 'df sorted' opnieuw toegewezen door de 'sorted'-functie toe te passen op elke rij. Hierdoor worden de waarden in elke rij van deze kolommen gesorteerd in oplopende volgorde.

Met het argument 'result type='expand'' wordt ervoor gezorgd dat de resultaten van de sorteerbewerking worden uitgebreid naar meerdere kolommen. Daarna wordt een booleaanse serie 'name not switched' gemaakt waarin wordt gecontroleerd of de waarden in de kolom 'player name' van 'df sorted' overeenkomen met de waarden in de kolom 'player name' van de oorspronkelijke DataFrame 'df games'.

Ten slotte wordt de DataFrame 'df games' bijgewerkt door alleen de rijen te behouden waarin de waarden in de kolom 'player name' overeenkomen met de waarden in de kolom 'player name' van 'df sorted'. Hierdoor wordt een gefilterde DataFrame verkregen waarin alleen de rijen staan waarin de speler niet van positie is gewisseld met de tegenstander, oftewel de dubbele records zijn verwijderd.

Deze applicatie heeft geleid tot de creatie van een nieuw CSV-bestand dat alle benodigde gegevens bevat om het model te trainen.

\section{Voorbereiden data}

\subsection{Overzicht}

Na het verkrijgen van het nieuwe CSV-bestand is de volgende essentiële stap het uitvoeren van gegevensreiniging. Om de data op te schonen, worden mogelijke inconsistenties, fouten of lege waarden geïdentificeerd en gecorrigeerd. Dit kan bijvoorbeeld inhouden dat, ontbrekende waarden worden ingevuld op basis van andere relevante gegevensbronnen en datatypen worden gevalideerd en aangepast voor consistente verwerking. Door dit zorgvuldige proces van gegevensreiniging wordt de kwaliteit en betrouwbaarheid van de dataset gewaarborgd. Dit proces zorgt ervoor dat de dataset klaar is voor verdere analyse en modeltraining. 

Bovendien biedt de reeds beschikbare data interessante mogelijkheden voor verdere analyse. Door het toepassen van statistische methoden, visualisaties en exploratieve technieken kunnen waardevolle patronen, trends en correlaties in de data worden ontdekt. Deze inzichten kunnen helpen bij het begrijpen van de schaakspelpatronen, spelersprestaties en andere interessante aspecten van het spel. 

\subsection{Data opschonen}

Na het inlezen van de dataset en het controleren van de gegevens, is het belangrijk om te zorgen voor de juiste datatypen en het opvullen, vervangen of verwijderen van ontbrekende waarden. Dit kan gedaan worden om de dataset te verfijnen en ervoor te zorgen dat het AI-model goed kan werken met de gegevens.

Het is van belang om ervoor te zorgen dat de juiste datatypen worden gebruikt voor elke kolom in de dataset. Dit kan gedaan worden met behulp van de functies en methoden die beschikbaar zijn in de pandas-bibliotheek. Bijvoorbeeld, als een kolom met datums als strings is ingeladen, kan deze worden omgezet naar het datetype 'datetime' om zo beter te werken met tijdsgerelateerde operaties en analyses.

Daarnaast is het belangrijk om ontbrekende waarden in de dataset aan te pakken. Dit kunnen waarden zijn die lege cellen of 'NaN' bevatten. Afhankelijk van de aard van de ontbrekende waarden en het specifieke probleem dat wordt aangepakt, kunnen verschillende methoden worden toegepast, zoals het opvullen van ontbrekende waarden met gemiddelde waarden, het vervangen van ontbrekende waarden door aannames op basis van andere gegevens, of het volledig verwijderen van rijen met ontbrekende waarden.

Voor dit specifieke voorbeeld zullen we ons richten op het csv-bestand dat betrekking heeft op de standaard tijdscategorie. De volgende stappen zullen ook worden toegepast op de andere twee csv-bestanden met betrekking tot de rapid en blitz records.

\begin{lstlisting}[language=Python]
    import pandas as pd                                 # Dataframe
    from pandas.api.types import CategoricalDtype
    data = pd.read_csv('games_std_filtered.csv',delimiter=',')
    data.head(100)
    data.info()
    ---  ------           --------------   -----  
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 185461 entries, 0 to 185460
    Data columns (total 8 columns):
    #   Column           Non-Null Count   Dtype  
    ---  ------           --------------   -----  
    0   date             185461 non-null  object 
    1   player_name      185461 non-null  object 
    2   opponent_name    185461 non-null  object 
    3   w                185461 non-null  float64
    4   k_chg            185461 non-null  float64
    5   opponent_rating  185461 non-null  int64  
    6   color            185461 non-null  object 
    7   current_rating   171774 non-null  float64
    dtypes: float64(3), int64(1), object(4)
    memory usage: 11.3+ MB
\end{lstlisting}

Het feit dat de kolom 'current rating' meer dan 15.000 null-waarden bevat, is een belangrijk gegeven dat moet worden onderzocht en opgelost. Het ontbreken van deze waarden kan verschillende redenen hebben, zoals technische problemen tijdens het verzamelen van de gegevens of het ontbreken van ratinginformatie voor specifieke spelers op bepaalde momenten.

Als er even teruggekeken kan worden naar de code die ervoor zorgt dat de 'current rating'-kolom wordt aangevuld is er een opmerkelijke lijn aangetroffen. Een if-else statement dat ervoor zorgt dat als een record leeg, er niets teruggegeven wordt. Dit werd gedaan om foutboodschappen te vermijden: 

\begin{lstlisting}[language=Python]
    # Finding all empty values in the "current_rating" column
    empty_current_rating = data[data['current_rating'].isnull()]
    print(empty_current_rating)
\end{lstlisting}

Het is interessant dat bij het onderzoeken van de lege waarden in de 'current rating'-kolom is opgemerkt dat het probleem niet alleen beperkt is tot oudere records, maar ook recentere spellen betreft. Dit suggereert dat er iets anders aan de hand is dan alleen verloren gegane of ongedocumenteerde gegevens in de loop der tijd.

Bij het bekijken van de code die verantwoordelijk is voor het aanvullen van de 'current rating'-kolom, is er een opvallende regel gevonden. Er wordt een if-else statement gebruikt waarbij als een record leeg is, er niets wordt afgedrukt om foutmeldingen te voorkomen.

\begin{lstlisting}[language=Python]
    return str(df_result.opponent_rating.values[0]) if not df_result.empty else ''
\end{lstlisting}

Deze bevinding werpt enkele vragen op over de oorspronkelijke bron van de gegevens en de kwaliteit ervan. Het is mogelijk dat er in de oorspronkelijke gegevensbron lege waarden zijn voor de 'current rating', wat heeft geleid tot de lege waarden in de dataset. Het is belangrijk om de gegevensbron grondig te analyseren en te begrijpen om de oorzaak van de lege waarden nauwkeurig te kunnen vaststellen.

Wat eigenaardig is, is dat de lege waarden in de 'current rating'-kolom niet worden veroorzaakt door een ontbrekende 'opponent rating'-waarde, zoals aanvankelijk gedacht. Na nader onderzoek van het csv-bestand is gebleken dat de zogenaamde 'dubbele' records eigenlijk nooit hebben bestaan en niet zijn gescrapet.

De oorzaak van dit fenomeen lijkt te liggen in het feit dat één van de twee spelers op het moment van de partij nog niet de titel van grootmeester had, wat niet wordt opgenomen in onze dataset. Dit heeft geleid tot het ontbreken van een van de records, waardoor de dubbelganger niet kon worden gedetecteerd.

Om dit probleem in onze dataset aan te pakken, zijn er twee mogelijke oplossingen. Één van die mogelijke oplossingen is het aanvullen van de ontbrekende gegevens om te proberen de lege 'current rating'-waarden van een speler aan te vullen. Dit door te kijken naar andere records waarin die speler heeft gespeeld tegen een andere tegenstander op diezelfde datum. Dit kan helpen om de ontbrekende rating van de speler te achterhalen. Echter, bij nader onderzoek bleek dat het vinden van een geschikte match voor aanvulling moeilijk was, omdat de rating van de speler op die specifieke datum niet beschikbaar was voor elke tegenstander. Bovendien bestond het risico dat deze aanvullende gegevens als uitschieters werden beschouwd tijdens het trainen van het AI-model, omdat ze mogelijk niet consistent waren met de algemene dataset.

Daarom is er gekozen voor de tweede oplossing, namelijk het verwijderen van de records waarin de 'current rating'-waarden leeg zijn. Dit resulteerde in het verlies van 6,7\% van de totale dataset (17.602 records van de 262.458 records) over alle csv-bestanden. Het csv-bestand van de standaard tijdscontrole had de grootste relatieve gegevensverlies, maar behield nog steeds meer dan 170.000 records met consistente gegevens, wat nog steeds een aanzienlijke dataset is om mee te werken.

\begin{lstlisting}[language=Python]
    # Dropping rows with empty values in the "current_rating" column
    data = data.dropna(subset=['current_rating'], inplace=False)
    data.info()
    ---  ------           --------------   -----  
    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 171774 entries, 0 to 185460
    Data columns (total 8 columns):
    #   Column           Non-Null Count   Dtype  
    ---  ------           --------------   -----  
    0   date             171774 non-null  object 
    1   player_name      171774 non-null  object 
    2   opponent_name    171774 non-null  object 
    3   w                171774 non-null  float64
    4   k_chg            171774 non-null  float64
    5   opponent_rating  171774 non-null  int64  
    6   color            171774 non-null  object 
    7   current_rating   171774 non-null  float64
    dtypes: float64(3), int64(1), object(4)
    memory usage: 11.8+ MB
\end{lstlisting}

Nu de dataset is opgeschoond en klaar is voor gebruik, kunnen we overgaan tot een kleine analysefase. Hieronder volgen enkele mogelijke analyses die kunnen worden uitgevoerd op de schaakdataset:

Winstpercentages: Bereken het winstpercentage voor de spelers met witte en zwarte stukken. Vergelijk deze percentages om te zien of er een significant verschil is. Dit kan worden gedaan voor elke tijdscontrole (standaard, rapid, blitz) om te kijken of er variaties zijn.

Tijdcontrole-effect: Vergelijk de winstpercentages en gelijkspelpercentages tussen de verschillende tijdscontroles (standaard, rapid, blitz). Analyseer of er significante verschillen zijn en of spelers andere speelstijlen aannemen bij verschillende tijdscontroles.

\section{Data Analyse}

Een belangrijk aspect dat naar voren kwam in de literatuurstudie is de invloed van de kleur van de stukken op de uitkomst van schaakpartijen. Traditioneel wordt aangenomen dat spelen met de witte stukken een voordeel kan opleveren. Nu we de volledige dataset hebben verkregen, biedt dit een uitgelezen kans om te onderzoeken of dit ook daadwerkelijk het geval is.

Het analyseren van de invloed van de kleur op de uitkomst van schaakpartijen kan inzicht geven in eventuele ongelijkheden tussen spelers die met wit spelen en spelers die met zwart spelen. Door het bestuderen van de winstpercentages, verliespercentages en gelijkspelpercentages van beide groepen, kunnen we de mogelijke impact van de kleur op de uitkomst beoordelen.

Een belangrijke stap in dit proces is het berekenen van de winstpercentages voor zowel spelers die met wit spelen als spelers die met zwart spelen. Dit kan worden gedaan door het aantal gewonnen partijen door spelers met wit te delen door het totale aantal gespeelde partijen met wit. Op dezelfde manier kan het winstpercentage voor spelers met zwart worden berekend.

Daarnaast kunnen we de verliespercentages en gelijkspelpercentages op dezelfde manier berekenen om een vollediger beeld te krijgen van de uitkomsten van schaakpartijen, rekening houdend met de kleur van de stukken.

Door deze statistische analyses uit te voeren en de resultaten te visualiseren, kunnen we conclusies trekken over de invloed van de kleur op de uitkomst van schaakpartijen. Het is mogelijk dat we bewijs vinden dat wijst op een significant voordeel voor spelers die met wit spelen, of dat de invloed van de kleur minder uitgesproken is dan verwacht. Deze bevindingen kunnen waardevolle inzichten opleveren en kunnen mogelijk worden gebruikt bij het ontwikkelen van AI-modellen voor schaakspelanalyse en -voorspelling.

\begin{lstlisting}[language=Python]
    # Filter the rows where color is white and calculate the percentage of different values of w
    white_w_frequency = data[data['color'] == 'white']['w'].value_counts(normalize=True) * 100

    # Filter the rows where color is black and calculate the percentage of different values of w
    black_w_frequency = data[data['color'] == 'black']['w'].value_counts(normalize=True) * 100

    # Results
    white_win_percentage = f"{white_w_frequency.get(1.0, 0):.2f}" 
    white_tie_percentage = f"{white_w_frequency.get(0.5, 0):.2f}"
    white_loss_percentage = f"{white_w_frequency.get(0.0, 0):.2f}"
    black_win_percentage = f"{black_w_frequency.get(1.0, 0):.2f}"
    black_tie_percentage = f"{black_w_frequency.get(0.5, 0):.2f}"
    black_loss_percentage = f"{black_w_frequency.get(0.0, 0):.2f}"

    # Display the results
    print("White winpercentage:", white_win_percentage, "%")
    print("White tiepercentage:", white_tie_percentage, "%")
    print("White losspercentage:", white_loss_percentage, "%")
    print("Black winpercentage:", black_win_percentage, "%")
    print("Black tiepercentage:", black_tie_percentage, "%")
    print("Black losspercentage:", black_loss_percentage, "%")
    ---  ------           --------------   -----  
    # winpercentages standard timeformat  
    White winpercentage: 28.70 %
    White tiepercentage: 53.29 %
    White losspercentage: 18.00 %
    Black winpercentage: 18.24 %
    Black tiepercentage: 53.69 %
    Black losspercentage: 28.07 %
    # winpercentages rapid timeformat  
    White winpercentage: 34.24 %
    White tiepercentage: 40.21 %
    White losspercentage: 25.55 %
    Black winpercentage: 26.30 %
    Black tiepercentage: 40.92 %
    Black losspercentage: 32.78 %
    # winpercentages blitz timeformat 
    White winpercentage: 39.54 %
    White tiepercentage: 28.78 %
    White losspercentage: 31.68 %
    Black winpercentage: 33.17 %
    Black tiepercentage: 28.79 %
    Black losspercentage: 38.03 % 
\end{lstlisting}

De bevindingen van ons onderzoek bevestigen de conclusies die eerder zijn gepresenteerd in de literatuurstudie. Uit onze analyse blijkt dat spelers die met de witte stukken spelen over het algemeen een winstpercentage hebben dat 6-10\% hoger is dan spelers die met de zwarte stukken spelen. Deze bevinding benadrukt het belang van het "tempo" voordeel dat verbonden is aan het spelen met wit, inclusief de mogelijkheid om de eerste zet te doen in een schaakpartij. 


Naast de algemene trend waarbij wit een voordeel heeft ten opzichte van zwart, is het opmerkelijk dat de tijdsduur van een schaakpartij ook invloed heeft op de uitkomst van de wedstrijd. Uit onze analyse blijkt dat naarmate spelers meer tijd krijgen om een partij te spelen, het aantal gelijkspelen toeneemt en het winstpercentage afneemt.

We hebben vastgesteld dat het percentage gelijkspelen met 13\% daalt van standaardtijdcontroles tot rapidtijdcontroles, en vervolgens nog eens met 12\% van rapidtijdcontroles tot blitztijdcontroles. Deze bevinding suggereert dat spelers in snellere tijdsformaten meer risico's nemen en vaker tot een beslissend resultaat proberen te komen, wat resulteert in minder gelijkspelen.

Opvallend genoeg stijgt het winstpercentage voor zowel wit als zwart met ongeveer 6\% in deze snellere tijdsformaten. Dit kan worden verklaard door het feit dat spelers onder tijdsdruk meer kans nemen, waardoor er vaker beslissende fouten worden gemaakt die leiden tot overwinningen voor beide kleuren.

Een plausibele verklaring voor de waargenomen trends is dat het spelen met een snellere tijdcontrole de spelers onder hogere tijdsdruk plaatst. De beperkte bedenktijd dwingt spelers om sneller zetten te doen, waardoor ze mogelijk minder tijd hebben om diepgaand te analyseren en verschillende zetvariaties te overwegen. Dit verhoogt het risico op blunders of het over het hoofd zien van belangrijke positionele overwegingen tijdens de partij.

De hogere tijdsdruk kan leiden tot meer impulsieve beslissingen en minder grondig denkwerk, waardoor spelers mogelijk vatbaarder worden voor fouten. Het is bekend dat zelfs ervaren schakers onder druk soms verkeerde zetten maken of cruciale tactische wendingen missen. Het snellere speeltempo kan dus resulteren in een verhoogde kans op dergelijke fouten, wat op zijn beurt kan bijdragen aan een hoger winstpercentage voor beide kleuren en een lager percentage gelijkspelen.

Een andere factor die van invloed kan zijn op de waargenomen trends is de neiging van spelers om met minder bedenktijd meer 'scherpe' en riskantere openingen te spelen. Deze openingen staan erom bekend dat ze afwijken van de beste zetten volgens de computeranalyse en worden doorgaans als minder solide beschouwd op het hoogste niveau. Echter, wanneer een speler tijdens de partij een variatie over het hoofd ziet, kan dit leiden tot een snelle en beslissende aanval.

Het spelen van dergelijke openingsvarianten met een hoger risico kan resulteren in een groter aantal overwinningen, maar tegelijkertijd ook in een hoger aantal nederlagen. Als een tegenstander goed voorbereid is en zich verweert tegen deze riskantere speelstijl, is de kans groter dat zij de partij winnen in plaats van dat deze in een gelijkspel eindigt.

Deze strategieën kunnen een impact hebben op de resultaten, aangezien spelers weten dat sommige mensen snel onder tijdsdruk terecht komen in snellere tijdscontroles, dat ze dan meer geneigd zijn om deze scherpere openingen te proberen. Dit kan verklaren waarom er een stijging is in het winstpercentage voor beide kleuren, omdat er meer mogelijkheden zijn voor snelle beslissende aanvallen, maar tegelijkertijd ook een daling in het percentage gelijkspelen, omdat de risicovollere speelstijl niet altijd succesvol is.

Het begrijpen van deze dynamiek is van belang bij het ontwikkelen van ons AI-model. We moeten rekening houden met de invloed van tijdsdruk op de spelers en de potentiële impact ervan op de nauwkeurigheid van de voorspellingen. Door factoren zoals tijdscontroles en de bijbehorende tijdsdruk in onze analyse op te nemen, streven we ernaar om een robuust en realistisch model te creëren dat rekening houdt met de verschillende aspecten van schaakpartijen. Daarom zal voor elk tijdsformaat een verschillend model opgebouwd worden om de schaakmatches te voorspellen. 

\section{Modeltraining}

